{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directed Acyclic Graphs (DAGs)\n",
    "Data pipelines are well expressed as Directed Acyclic Graphs. The conceptual framework of data pipelines will help you better organize and execute everyday data engineering tasks<br>\n",
    "DAGS consist of vertices, or nodes & directed edges that connect those nodes. They have no direction and do not contain cycles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Airflow\n",
    "Airflow allows users to write DAGs in python that run on a schedile and/or from an externla trigger. Airflow is simple to maintain and can run data itself, or trigger exyternal tools (Redshift, spark, hadoop, presto, etc) during execution.\n",
    "\n",
    "It consists of:\n",
    "* **scheduler:** for orchestrating execution of jobs on a trigger or schdule\n",
    "* **Work queue:** Which holds the state of the running dags and tasks\n",
    "* **Worker processes:** That executes the operations defined in each DAG\n",
    "* **Database:** Which saves credentials, connections, history and configuration\n",
    "* **Web Interface:** Which provides a control dashboard for users and maintainers\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "\n",
    "def greet():\n",
    "    logging.info('Hello World')\n",
    "\n",
    "dag = DAG(\n",
    "    description='Introduction to DAGs',\n",
    "    start_date=datetime.datetime.now(),\n",
    "    dag_id=\"001\"\n",
    ")\n",
    "\n",
    "### Order of Operations for an Airflow DAG\n",
    "1. The airflow scheduler starts DAGs based on time or external triggers\n",
    "2. Once a DAG is started, the scheduler looks at the steps within the DAG and detrmines which steps can run by looking at their dependencies\n",
    "3. The scheduler places runnable steps in the queue\n",
    "4. Workers pick up those tasks and run them\n",
    "5. Once the worker has finished running the step, the final status of the task is recorded and additional tasks are placed by the scheduler until all taska are complete.\n",
    "6. Once all taska have been completed, the DAG is complete."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operators\n",
    "hello_world_task = PythonOperator(task_id = 'hello_world', ...)\n",
    "goodbye_world_task = PythonOperator(task_id = 'goodbye_world', ...)\n",
    "\n",
    "hello_world_task >> goodbye_world_task\n",
    "This means hello world task will come before the goodbye one. Alternatively, we can use:\n",
    "a.set_upstream(b) means a comes before b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78a6b0ca07cb5847e8af2b4b21b5976c3bf42dbf493882f320c4441d3da3d452"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
